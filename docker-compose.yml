version: '3.8'

services:
  # -------------------------------------------------------------------
  # ZooKeeper Service
  # -------------------------------------------------------------------
  zookeeper:
    image: bitnami/zookeeper:3.8.0
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOO_MAX_CLIENT_CNXNS=1000
    volumes:
      - zookeeper_data:/bitnami/zookeeper
    networks:
      - analytics-net
    healthcheck:
      test: ["CMD", "zkServer.sh", "status"]
      interval: 10s
      timeout: 5s
      retries: 5

  # -------------------------------------------------------------------
  # Kafka Service
  # -------------------------------------------------------------------
  kafka:
    image: bitnami/kafka:3.4.0
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_BROKER_ID=1
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_CFG_NUM_PARTITIONS=3
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=1
    volumes:
      - kafka_data:/bitnami/kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - analytics-net
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--list", "--bootstrap-server", "localhost:9092"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 30s

  # -------------------------------------------------------------------
  # Kafka Producer
  # -------------------------------------------------------------------
  kafka-producer:
    build:
      context: ./kafka
    container_name: kafka-producer
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC=retail_transactions
      - KAFKA_PRODUCER_TIMEOUT_MS=30000
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_ADVERTISED_LISTENERS=kafka:9092
    volumes:
      - ./kafka:/app
    command: ["python", "kafka_producer.py"]
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - analytics-net
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep python | grep kafka_producer.py || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  # -------------------------------------------------------------------
  # Spark Cluster
  # -------------------------------------------------------------------
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_DAEMON_MEMORY=2g
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"
      - "7077:7077"
    networks:
      - analytics-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 1m

  spark-worker:
    image: bitnami/spark:3.5.0
    container_name: spark-worker
    hostname: spark-worker
    ports: ["8081:8081"]
    environment:
      # For using kafka-python(needs connectors to be added) over SparkNative
      - SPARK_PYTHON=/opt/bitnami/spark/bin/python
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081
      # For using SparkNative over kafka-python
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_TOPIC=retail_transactions
      - KAFKA_CONSUMER_GROUP=spark-consumer
      - MONGO_URI=mongodb://mongodb:27017
      - CHECKPOINT_LOCATION= /tmp/spark-checkpoint
    depends_on: [spark-master]
    networks: [analytics-net]
    user: "1001:1001"
    volumes:
      - ./spark:/opt/bitnami/spark/app
    command: >
      bash -c "
      /opt/bitnami/scripts/spark/run.sh &
      sleep 10 &&  # Wait for master
      /opt/bitnami/spark/bin/spark-submit \
        --master spark://spark-master:7077 \
        --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
        /opt/bitnami/spark/app/spark_consumer.py
      "
    #command: >
    #  sh -c "
    #  spark-submit --master spark://spark-master:7077 /opt/bitnami/spark/app/spark_consumer.py &
    #  sleep infinity
    #  "
    #command: ["python3", "spark_consumer.py"]
    #command: ["spark-submit", "--master", "spark://spark-master:7077", "/opt/bitnami/spark/app/spark_consumer.py", "&&", "tail", "-f", "/dev/null"]
    restart: unless-stopped
  # -------------------------------------------------------------------
  # Database Services
  # -------------------------------------------------------------------
  mongodb:
    image: mongo:6.0.5
    container_name: mongodb
    environment:
      - MONGO_INITDB_ROOT_USERNAME=root
      - MONGO_INITDB_ROOT_PASSWORD=example
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    networks:
      - analytics-net
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s

  postgres:
    image: postgres:15.3
    container_name: postgres
    environment:
      - POSTGRES_USER=superset
      - POSTGRES_PASSWORD=superset
      - POSTGRES_DB=superset
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - analytics-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U superset"]
      interval: 10s
      timeout: 5s

  # -------------------------------------------------------------------
  # UI Services
  # -------------------------------------------------------------------
  mongo-express:
    image: mongo-express:1.0.0
    container_name: mongo-express
    environment:
      - ME_CONFIG_MONGODB_SERVER=mongodb
      - ME_CONFIG_MONGODB_ADMINUSERNAME=root
      - ME_CONFIG_MONGODB_ADMINPASSWORD=example
    ports:
      - "8085:8085"
    depends_on:
      mongodb:
        condition: service_healthy
    networks:
      - analytics-net

  superset:
    image: apache/superset:2.1.0
    container_name: superset
    environment:
      - SUPERSET_SECRET_KEY=supersecret
      - SUPERSET_LOAD_EXAMPLES=yes
      - DATABASE_HOST=postgres
      - DATABASE_USER=superset
      - DATABASE_PASSWORD=superset
      - DATABASE_NAME=superset
    ports:
      - "8088:8088"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - superset_data:/app/superset_home
    networks:
      - analytics-net

volumes:
  zookeeper_data:
  kafka_data:
  mongo_data:
  postgres_data:
  superset_data:

networks:
  analytics-net:
    driver: bridge
    # sudo lsof -i :5432
    # sudo kill -9 <PID>
    # netstat -tuln | grep -E '5432|27017'